{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acdce49b",
   "metadata": {},
   "source": [
    "# Machine Learning: Assignment 5 \n",
    "## SVM plus Other Classification Method (max. 10p)\n",
    "\n",
    "The dataset for the exercise is \"Date Fruit Datasets\" file you can find from [Date_Fruit_Datasets.xlsx](data/Date_Fruit_Datasets.xlsx), which contains 898 rows and 34 columns of data about dates and a column telling the species of dates. \n",
    "\n",
    "There are **seven** (**7**) date fruit species in the dataset, so this is kind of **multi-class classification problem**.\n",
    "\n",
    "More information about the data and related research: [https://www.muratkoklu.com/datasets/](https://www.muratkoklu.com/datasets/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6a4adbdbab8843",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T11:36:29.339723800Z",
     "start_time": "2023-12-15T11:36:29.157214700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write Your information in here\n",
    "student_name = \"Kristian Pekkanen, Joonas Lahti\"\n",
    "student_id = \"AD0462, AC6855\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a121bf38fbb46",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Assignment 5.1\n",
    "### Topic: Data Preprocessing (2 points)\n",
    "The dataset has a class variable (*target*) in the last column.\n",
    "\n",
    "Let's do the following preprocessing steps with the dataset:\n",
    "\n",
    "1. Load the data into the `DataFrame`.\n",
    "2. Name the columns of the `DataFrame` according to the material.\n",
    "3. Preprocess the material\n",
    "   * Optimize the data input to the machine learning model\n",
    "   * You can remove \"unnecessary features\" at your discretion\n",
    "   * Handling of abnormal (outliers) or empty data values\n",
    "   * Remember that all categories should be numeric\n",
    "4. Scale column values by normalizing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a340a5f6dc44e75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T11:36:30.425819200Z",
     "start_time": "2023-12-15T11:36:29.174168Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Write your code in this cell\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df = pd.read_excel(\"./data/Date_Fruit_Datasets.xlsx\", sheet_name=\"Date_Fruit_Datasets\") \n",
    "\n",
    "columns = [\n",
    "    \"AREA\",\n",
    "    \"PERIMETER\",\n",
    "    \"MAJOR_AXIS\",\n",
    "    \"MINOR_AXIS\",\n",
    "    \"ECCENTRICITY\",\n",
    "    \"EQDIASQ\",\n",
    "    \"SOLIDITY\",\n",
    "    \"CONVEX_AREA\",\n",
    "    \"EXTENT\",\n",
    "    \"ASPECT_RATIO\",\n",
    "    \"ROUNDNESS\",\n",
    "    \"COMPACTNESS\",\n",
    "    \"SHAPEFACTOR_1\",\n",
    "    \"SHAPEFACTOR_2\",\n",
    "    \"SHAPEFACTOR_3\",\n",
    "    \"SHAPEFACTOR_4\",\n",
    "    \"MeanRR\",\n",
    "    \"MeanRG\",\n",
    "    \"MeanRB\",\n",
    "    \"StdDevRR\",\n",
    "    \"StdDevRG\",\n",
    "    \"StdDevRB\",\n",
    "    \"SkewRR\",\n",
    "    \"SkewRG\",\n",
    "    \"SkewRB\",\n",
    "    \"KurtosisRR\",\n",
    "    \"KurtosisRG\",\n",
    "    \"KurtosisRB\",\n",
    "    \"EntropyRR\",\n",
    "    \"EntropyRG\",\n",
    "    \"EntropyRB\",\n",
    "    \"ALLdaub4RR\",\n",
    "    \"ALLdaub4RG\",\n",
    "    \"ALLdaub4RB\",\n",
    "    \"Class\",\n",
    "]\n",
    "\n",
    "df.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "771acbee732b053",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T11:36:30.443770200Z",
     "start_time": "2023-12-15T11:36:30.427812800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Plotting features\n",
    "\n",
    "#Dropping unnecessary columns from the dataset.\n",
    "df = df.drop([\"MeanRR\", \"MeanRG\", \"MeanRB\", \"StdDevRR\", \"StdDevRG\", \"StdDevRB\", \"SkewRR\", \"SkewRG\", \"SkewRB\", \"KurtosisRR\", \"KurtosisRG\", \"KurtosisRB\", \"EntropyRR\", \"EntropyRG\", \"EntropyRB\", \"ALLdaub4RR\", \"ALLdaub4RG\", \"ALLdaub4RB\"], axis=1)\n",
    "df = df.drop([\"Class\"], axis=1)\n",
    "\n",
    "#Ouliers or empty data values\n",
    "df = df.apply(lambda x: x.str.re√•lace(',', '.', regex=False) if x.dtype == 0 else x)\n",
    "\n",
    "#Converting the data to float \n",
    "scaler = StandardScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a71a4be9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T11:36:30.486710400Z",
     "start_time": "2023-12-15T11:36:30.445765700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: Index(['AREA', 'PERIMETER', 'MAJOR_AXIS', 'MINOR_AXIS', 'ECCENTRICITY',\n",
      "       'EQDIASQ', 'SOLIDITY', 'CONVEX_AREA', 'EXTENT', 'ASPECT_RATIO',\n",
      "       'ROUNDNESS', 'COMPACTNESS', 'SHAPEFACTOR_1', 'SHAPEFACTOR_2',\n",
      "       'SHAPEFACTOR_3', 'SHAPEFACTOR_4'],\n",
      "      dtype='object')\n",
      "First row by position: AREA             1.155640\n",
      "PERIMETER        0.783942\n",
      "MAJOR_AXIS       0.604507\n",
      "MINOR_AXIS       1.311643\n",
      "ECCENTRICITY    -1.129568\n",
      "EQDIASQ          1.075704\n",
      "SOLIDITY         0.708628\n",
      "CONVEX_AREA      1.108752\n",
      "EXTENT           0.871873\n",
      "ASPECT_RATIO    -0.046797\n",
      "ROUNDNESS        1.125433\n",
      "COMPACTNESS      1.091228\n",
      "SHAPEFACTOR_1   -0.069867\n",
      "SHAPEFACTOR_2   -0.688443\n",
      "SHAPEFACTOR_3    1.169934\n",
      "SHAPEFACTOR_4    0.240467\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Answers to the assignment. Note! Do not edit this cell, just run it after you complete the task.\n",
    "# The DataFrame should be in the df variable.\n",
    "print(f'Columns: {df.columns}')\n",
    "print(f'First row by position: {df.iloc[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f244b54",
   "metadata": {},
   "source": [
    "## Assignment 5.2: Training and Testing Data (2 points)\n",
    "\n",
    "Split the data into training and testing data using the [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function of the `scikit-learn` library.\n",
    "Put *75%* of the data in training data.\n",
    "\n",
    "1. Save the training data and its class variable to the variables `X_train`, `y_train`,\n",
    "2. Save the test data to the variables `X_test`, `y_test`.\n",
    "\n",
    "If you think there are unnecessary variables in the data, you should remove them at this stage.\n",
    "\n",
    "Use the number `1550` as the random seed and the size of the test data *25%*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09c8e802",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T11:36:30.487655600Z",
     "start_time": "2023-12-15T11:36:30.461722600Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# TODO: Write your implementation in this cell.\n",
    "\n",
    "# TODO: Choose the appropriate scaling method\n",
    "# TODO: Normalize the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_excel(\"./data/Date_Fruit_Datasets.xlsx\", sheet_name=\"Date_Fruit_Datasets\")\n",
    "X = df.drop([\"Class\"], axis=1)\n",
    "y = df[\"Class\"]\n",
    "\n",
    "# TODO: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1550)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3075f9ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T11:36:30.497662300Z",
     "start_time": "2023-12-15T11:36:30.474688300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898\n",
      "673\n",
      "225\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA</th>\n",
       "      <th>PERIMETER</th>\n",
       "      <th>MAJOR_AXIS</th>\n",
       "      <th>MINOR_AXIS</th>\n",
       "      <th>ECCENTRICITY</th>\n",
       "      <th>EQDIASQ</th>\n",
       "      <th>SOLIDITY</th>\n",
       "      <th>CONVEX_AREA</th>\n",
       "      <th>EXTENT</th>\n",
       "      <th>ASPECT_RATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>SkewRB</th>\n",
       "      <th>KurtosisRR</th>\n",
       "      <th>KurtosisRG</th>\n",
       "      <th>KurtosisRB</th>\n",
       "      <th>EntropyRR</th>\n",
       "      <th>EntropyRG</th>\n",
       "      <th>EntropyRB</th>\n",
       "      <th>ALLdaub4RR</th>\n",
       "      <th>ALLdaub4RG</th>\n",
       "      <th>ALLdaub4RB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>363778</td>\n",
       "      <td>2324.1609</td>\n",
       "      <td>857.5090</td>\n",
       "      <td>541.6883</td>\n",
       "      <td>0.7752</td>\n",
       "      <td>680.5707</td>\n",
       "      <td>0.9859</td>\n",
       "      <td>368999</td>\n",
       "      <td>0.6962</td>\n",
       "      <td>1.5830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5565</td>\n",
       "      <td>4.1236</td>\n",
       "      <td>8.9859</td>\n",
       "      <td>4.0427</td>\n",
       "      <td>-11916909568</td>\n",
       "      <td>-12828743680</td>\n",
       "      <td>-16592906240</td>\n",
       "      <td>29.3568</td>\n",
       "      <td>30.2898</td>\n",
       "      <td>34.5888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>137932</td>\n",
       "      <td>1404.5460</td>\n",
       "      <td>524.6572</td>\n",
       "      <td>335.7947</td>\n",
       "      <td>0.7684</td>\n",
       "      <td>419.0710</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>139753</td>\n",
       "      <td>0.7834</td>\n",
       "      <td>1.5624</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2365</td>\n",
       "      <td>2.6462</td>\n",
       "      <td>3.0183</td>\n",
       "      <td>2.6045</td>\n",
       "      <td>-16443756544</td>\n",
       "      <td>-16013483008</td>\n",
       "      <td>-15180389376</td>\n",
       "      <td>54.1920</td>\n",
       "      <td>54.1965</td>\n",
       "      <td>52.2736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>297174</td>\n",
       "      <td>2155.9590</td>\n",
       "      <td>779.7753</td>\n",
       "      <td>488.4755</td>\n",
       "      <td>0.7795</td>\n",
       "      <td>615.1208</td>\n",
       "      <td>0.9716</td>\n",
       "      <td>305852</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>1.5963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7421</td>\n",
       "      <td>8.8575</td>\n",
       "      <td>7.7524</td>\n",
       "      <td>4.7820</td>\n",
       "      <td>-8952644608</td>\n",
       "      <td>-9902926848</td>\n",
       "      <td>-11451906048</td>\n",
       "      <td>25.8247</td>\n",
       "      <td>28.4548</td>\n",
       "      <td>32.2477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>379703</td>\n",
       "      <td>2327.3159</td>\n",
       "      <td>808.6260</td>\n",
       "      <td>603.5130</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>695.3077</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>386849</td>\n",
       "      <td>0.7885</td>\n",
       "      <td>1.3399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4954</td>\n",
       "      <td>3.4431</td>\n",
       "      <td>3.6240</td>\n",
       "      <td>3.1232</td>\n",
       "      <td>-67456614400</td>\n",
       "      <td>-60271841280</td>\n",
       "      <td>-51568693248</td>\n",
       "      <td>65.5561</td>\n",
       "      <td>62.4925</td>\n",
       "      <td>57.4187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>265701</td>\n",
       "      <td>1968.8020</td>\n",
       "      <td>746.8929</td>\n",
       "      <td>454.7724</td>\n",
       "      <td>0.7933</td>\n",
       "      <td>581.6365</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>267851</td>\n",
       "      <td>0.7619</td>\n",
       "      <td>1.6423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>2.2009</td>\n",
       "      <td>2.3465</td>\n",
       "      <td>2.5310</td>\n",
       "      <td>-44338049024</td>\n",
       "      <td>-38484541440</td>\n",
       "      <td>-32898990080</td>\n",
       "      <td>62.8217</td>\n",
       "      <td>58.8671</td>\n",
       "      <td>55.4206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AREA  PERIMETER  MAJOR_AXIS  MINOR_AXIS  ECCENTRICITY   EQDIASQ  \\\n",
       "686  363778  2324.1609    857.5090    541.6883        0.7752  680.5707   \n",
       "210  137932  1404.5460    524.6572    335.7947        0.7684  419.0710   \n",
       "768  297174  2155.9590    779.7753    488.4755        0.7795  615.1208   \n",
       "520  379703  2327.3159    808.6260    603.5130        0.6656  695.3077   \n",
       "71   265701  1968.8020    746.8929    454.7724        0.7933  581.6365   \n",
       "\n",
       "     SOLIDITY  CONVEX_AREA  EXTENT  ASPECT_RATIO  ...  SkewRB  KurtosisRR  \\\n",
       "686    0.9859       368999  0.6962        1.5830  ...  0.5565      4.1236   \n",
       "210    0.9870       139753  0.7834        1.5624  ... -0.2365      2.6462   \n",
       "768    0.9716       305852  0.6638        1.5963  ...  0.7421      8.8575   \n",
       "520    0.9815       386849  0.7885        1.3399  ... -0.4954      3.4431   \n",
       "71     0.9920       267851  0.7619        1.6423  ...  0.1484      2.2009   \n",
       "\n",
       "     KurtosisRG  KurtosisRB    EntropyRR    EntropyRG    EntropyRB  \\\n",
       "686      8.9859      4.0427 -11916909568 -12828743680 -16592906240   \n",
       "210      3.0183      2.6045 -16443756544 -16013483008 -15180389376   \n",
       "768      7.7524      4.7820  -8952644608  -9902926848 -11451906048   \n",
       "520      3.6240      3.1232 -67456614400 -60271841280 -51568693248   \n",
       "71       2.3465      2.5310 -44338049024 -38484541440 -32898990080   \n",
       "\n",
       "     ALLdaub4RR  ALLdaub4RG  ALLdaub4RB  \n",
       "686     29.3568     30.2898     34.5888  \n",
       "210     54.1920     54.1965     52.2736  \n",
       "768     25.8247     28.4548     32.2477  \n",
       "520     65.5561     62.4925     57.4187  \n",
       "71      62.8217     58.8671     55.4206  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answers to the assignment. Note! Do not edit this cell, just run it after you complete the task.\n",
    "\n",
    "df_X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "\n",
    "print(len(df))\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "df_X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013f0442",
   "metadata": {},
   "source": [
    "## Task 5.3: Implement Support Vector Machine Classification (2 points)\n",
    "\n",
    "1. Use the `scikit-learn` library's *Linear Support Vector Classification* function to train a classifier with your training data that classifies each date fruit species.\n",
    "\n",
    "2. Create predictions for the data points of your test data in the `y_pred` variable.\n",
    "\n",
    "3. Use the `metrics` module to make a [classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) for the predictions of your test data. Save results to the `cr` variable.\n",
    "\n",
    "4. Use the `metrics` module to make a **confusion matrix** and store it in the `cm` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c18db916",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T11:36:30.505605400Z",
     "start_time": "2023-12-15T11:36:30.491643900Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joonas\\Desktop\\KouluJamk\\ml-assignments\\.venv\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Joonas\\Desktop\\KouluJamk\\ml-assignments\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Joonas\\Desktop\\KouluJamk\\ml-assignments\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Joonas\\Desktop\\KouluJamk\\ml-assignments\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Joonas\\Desktop\\KouluJamk\\ml-assignments\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write your implementation in this cell.\n",
    "# TODO: use LinearSVC.\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "svm_model = LinearSVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Generate classification report\n",
    "cr = classification_report(y_test, y_pred)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9592c9f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T11:36:30.565444800Z",
     "start_time": "2023-12-15T11:36:30.508599300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       BERHI       0.00      0.00      0.00        19\n",
      "      DEGLET       0.00      0.00      0.00        17\n",
      "       DOKOL       0.00      0.00      0.00        54\n",
      "       IRAQI       0.12      0.67      0.20        21\n",
      "      ROTANA       0.00      0.00      0.00        44\n",
      "      SAFAVI       0.84      0.87      0.85        47\n",
      "       SOGAY       0.34      0.78      0.47        23\n",
      "\n",
      "    accuracy                           0.32       225\n",
      "   macro avg       0.18      0.33      0.22       225\n",
      "weighted avg       0.22      0.32      0.25       225\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 0  0  0 16  0  1  2]\n",
      " [ 1  0  0  6  0  0 10]\n",
      " [ 2  0  0 38  0  0 14]\n",
      " [ 0  0  0 14  0  7  0]\n",
      " [ 1  0  0 35  0  0  8]\n",
      " [ 0  0  0  5  0 41  1]\n",
      " [ 0  0  0  5  0  0 18]]\n"
     ]
    }
   ],
   "source": [
    "# Answers to the assignment. Note! Do not edit this cell, just run it after you complete the task.\n",
    "# The results are in cm and cr variables.\n",
    "print(f'Classification report:\\n {cr}')\n",
    "print(f'Confusion matrix:\\n {cm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797f9479",
   "metadata": {},
   "source": [
    "## Assignment 5.4: Comparison with another ML method and analysis of the results (2 points)\n",
    "\n",
    "Verbally interpret the obtained test results.\n",
    "* How well the support vector did in the classification task\n",
    "\n",
    "For comparison, try teaching the model using another classification method:\n",
    "* The method can be **RandomForest** (or if you want **DecisionTree** etc., but still justify your choice)\n",
    "So you can freely select the ML classification method used in this comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fcb216fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T11:36:30.569436500Z",
     "start_time": "2023-12-15T11:36:30.525553200Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joonas\\Desktop\\KouluJamk\\ml-assignments\\.venv\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Joonas\\Desktop\\KouluJamk\\ml-assignments\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine (SVM) Results:\n",
      "Accuracy: 0.39\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       BERHI       0.00      0.00      0.00        19\n",
      "      DEGLET       0.00      0.00      0.00        17\n",
      "       DOKOL       0.31      0.74      0.44        54\n",
      "       IRAQI       0.00      0.00      0.00        21\n",
      "      ROTANA       0.00      0.00      0.00        44\n",
      "      SAFAVI       0.49      0.96      0.65        47\n",
      "       SOGAY       0.60      0.13      0.21        23\n",
      "\n",
      "    accuracy                           0.39       225\n",
      "   macro avg       0.20      0.26      0.19       225\n",
      "weighted avg       0.24      0.39      0.26       225\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 0  0  9  0  0 10  0]\n",
      " [ 0  0 13  0  0  2  2]\n",
      " [ 0  0 40  0  0 14  0]\n",
      " [ 0  0  3  0  0 18  0]\n",
      " [ 0  0 42  0  0  2  0]\n",
      " [ 0  0  2  0  0 45  0]\n",
      " [ 0  0 20  0  0  0  3]]\n",
      "\n",
      "RandomForest Results:\n",
      "Accuracy: 0.90\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       BERHI       0.94      0.79      0.86        19\n",
      "      DEGLET       0.52      0.65      0.58        17\n",
      "       DOKOL       0.94      0.91      0.92        54\n",
      "       IRAQI       0.83      0.95      0.89        21\n",
      "      ROTANA       0.98      0.95      0.97        44\n",
      "      SAFAVI       1.00      1.00      1.00        47\n",
      "       SOGAY       0.82      0.78      0.80        23\n",
      "\n",
      "    accuracy                           0.90       225\n",
      "   macro avg       0.86      0.86      0.86       225\n",
      "weighted avg       0.91      0.90      0.90       225\n",
      "\n",
      "Confusion Matrix:\n",
      " [[15  0  0  4  0  0  0]\n",
      " [ 0 11  3  0  0  0  3]\n",
      " [ 0  5 49  0  0  0  0]\n",
      " [ 1  0  0 20  0  0  0]\n",
      " [ 0  1  0  0 42  0  1]\n",
      " [ 0  0  0  0  0 47  0]\n",
      " [ 0  4  0  0  1  0 18]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joonas\\Desktop\\KouluJamk\\ml-assignments\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Joonas\\Desktop\\KouluJamk\\ml-assignments\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Joonas\\Desktop\\KouluJamk\\ml-assignments\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write your implementation in this cell.\n",
    "\n",
    "# TODO: Implementation of another Machine Learning Classification method.\n",
    "# TODO: The method can be RandomForest or any other method that works with this data \"well enough\".\n",
    "\n",
    "# TODO: Write your implementation in this cell.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_model = LinearSVC(random_state=1550)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# RandomForest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=1550)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate SVM\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "report_svm = classification_report(y_test, y_pred_svm)\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "# Evaluate RandomForest\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "report_rf = classification_report(y_test, y_pred_rf)\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "# Interpret the results\n",
    "print(\"Support Vector Machine (SVM) Results:\")\n",
    "print(f\"Accuracy: {accuracy_svm:.2f}\")\n",
    "print(\"Classification Report:\\n\", report_svm)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_svm)\n",
    "\n",
    "print(\"\\nRandomForest Results:\")\n",
    "print(f\"Accuracy: {accuracy_rf:.2f}\")\n",
    "print(\"Classification Report:\\n\", report_rf)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b091213e",
   "metadata": {},
   "source": [
    "## Assignment 5.5: Analysis of the results (2 points)\n",
    "Let's do comparison of Different Classification Models used in this assignment.\n",
    "* Compare the classification results of SVM and Selected Classification models.\n",
    "* Compare the obtained results and interpret the results verbally.\n",
    "* Compare the **accuracy** and **confusion matrix** of the classification results for both methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32dd2313",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-15T11:36:30.570443600Z",
     "start_time": "2023-12-15T11:36:30.540514500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine (SVM) Results:\n",
      "Accuracy: 0.39\n",
      "Confusion Matrix:\n",
      " [[ 0  0  9  0  0 10  0]\n",
      " [ 0  0 13  0  0  2  2]\n",
      " [ 0  0 40  0  0 14  0]\n",
      " [ 0  0  3  0  0 18  0]\n",
      " [ 0  0 42  0  0  2  0]\n",
      " [ 0  0  2  0  0 45  0]\n",
      " [ 0  0 20  0  0  0  3]]\n",
      "\n",
      "RandomForest Results:\n",
      "Accuracy: 0.90\n",
      "Confusion Matrix:\n",
      " [[15  0  0  4  0  0  0]\n",
      " [ 0 11  3  0  0  0  3]\n",
      " [ 0  5 49  0  0  0  0]\n",
      " [ 1  0  0 20  0  0  0]\n",
      " [ 0  1  0  0 42  0  1]\n",
      " [ 0  0  0  0  0 47  0]\n",
      " [ 0  4  0  0  1  0 18]]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compare the accuracy of the classification results of both classification methods.\n",
    "# TODO: Compare the confusion matrix of both classification methods with each other.\n",
    "\n",
    "# SVM Results\n",
    "print(\"Support Vector Machine (SVM) Results:\")\n",
    "print(f\"Accuracy: {accuracy_svm:.2f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_svm)\n",
    "\n",
    "# RandomForest Results\n",
    "print(\"\\nRandomForest Results:\")\n",
    "print(f\"Accuracy: {accuracy_rf:.2f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae010b45",
   "metadata": {},
   "source": [
    "Q: Are there other good classification methods to apply with this dataset or any other way to improve the classification results?"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
